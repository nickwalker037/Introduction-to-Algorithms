when we look at input sizes large enough to make only the order of growth of the running time relevant, we are studying the asymptotic efficiency of algorithms
- that is, we are concerned with how the running time of an algorithm increases with the size of the input in the limit, as the size of the input increases without bound 
        - usually an algorithm that is asymptotically more efficient will be the best choice for all but very small inputs

3.1 Asymptotic Notation
- this section defines the basic asymptotic notations and also introduces some common abuses
