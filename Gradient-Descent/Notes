Model-fitting often reduces to optimization
- Ex. maximizing the likelihood of observed data over a family of generative models

What problem is gradient descent trying to solve?
- Unconstrained Optimization
    - for a given real-valued function f: Rn —> R defined on an n-dimensional Euclidean space, the goal is min f(x)
- but there are ways to extend gradient descent to handle constraints 
    - like projecting back to the feasible region

Unconstrained Optimization: 
- there are no constraints, and the only consideration is the objective function
- there are various ways to transform constrained problems into unconstrained ones
    - Lagrangian relaxation
    - Barrier functions

Think of it as we’re releasing a ball at some random point of the graph of function f, and the algorithm terminates at the final resting point of this ball (after gravity has done its work) (and you’re looking for a min value)
    - at each step, you use the derivative of f to decide which direction to move in
    - minimizing f using gradient descent may yield a different local minimum depending on the start position

